{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13154571,"sourceType":"datasetVersion","datasetId":8334656},{"sourceId":13515228,"sourceType":"datasetVersion","datasetId":8581045}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CREATING ORGANIZED TOMATO POTATO DATASET","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# --- CONFIGURATION ---\nSOURCE_DIRECTORY = '/kaggle/input/combined-dataset1to4-modified/Combined_Dataset1to4'\nOUTPUT_DIRECTORY = 'Organized_Dataset_Tomato_Potato' # New output folder\n\n# ❗ KEY CHANGE: Define a list of the only plant categories you want to process.\n# The script will ignore any folder that doesn't belong to these categories.\nCLASSES_TO_PROCESS = ['Tomato', 'Potato']\n\n# --- SCRIPT LOGIC ---\n\nPLANT_MAP = {\n    'Apple': 'Apple', 'Cotton': 'Cotton', 'Rice': 'Rice',\n    'Blueberry': 'Blueberry', 'Cherry': 'Cherry', 'Corn': 'Corn', 'Maize': 'Corn',\n    'Grape': 'Grape', 'Orange': 'Orange', 'Peach': 'Peach', 'Pepper': 'Pepper',\n    'Potato': 'Potato', 'Raspberry': 'Raspberry', 'Soybean': 'Soybean',\n    'Squash': 'Squash', 'Strawberry': 'Strawberry', 'Sugarcane': 'Sugarcane',\n    'Tomato': 'Tomato', 'Wheat': 'Wheat'\n}\n\ndef get_new_names(original_name):\n    \"\"\"Parses the original folder name to get the new category and subfolder name.\"\"\"\n    name_lower = original_name.lower()\n\n    if '_on_' in name_lower:\n        parts = original_name.split('_on_')\n        return parts[1].capitalize(), parts[0].replace('_', ' ')\n    if '_in_' in name_lower:\n        parts = original_name.split('_in_')\n        return parts[1].capitalize(), parts[0].replace('_', ' ')\n    \n    for keyword, category in PLANT_MAP.items():\n        if keyword.lower() in name_lower:\n            new_subfolder_name = original_name.replace(keyword, '').replace('___', '_').strip(' _')\n            new_subfolder_name = new_subfolder_name.replace('(maize)', '').replace('(including_sour)', '').strip(' _')\n            \n            if not new_subfolder_name or new_subfolder_name.lower() == 'healthy':\n                new_subfolder_name = 'healthy'\n                \n            return category, new_subfolder_name.replace('_', ' ').capitalize()\n\n    return \"Unclassified\", original_name\n\ndef main():\n    \"\"\"Main function to create the new structure and copy files.\"\"\"\n    print(f\"Preparing to organize folders for {CLASSES_TO_PROCESS}...\")\n    print(f\"Source: '{SOURCE_DIRECTORY}'\")\n\n    try:\n        all_folders = [f for f in os.listdir(SOURCE_DIRECTORY) if os.path.isdir(os.path.join(SOURCE_DIRECTORY, f))]\n        print(f\"Found {len(all_folders)} total folders to check.\")\n    except FileNotFoundError:\n        print(f\"❌ Error: The source directory was not found: '{SOURCE_DIRECTORY}'\")\n        return\n        \n    os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)\n    \n    processed_count = 0\n    for original_folder_name in all_folders:\n        source_path = os.path.join(SOURCE_DIRECTORY, original_folder_name)\n        \n        category, new_subfolder_name = get_new_names(original_folder_name)\n        \n        # ❗ KEY CHANGE: Check if the detected category is in our target list.\n        if category in CLASSES_TO_PROCESS:\n            # If it is, proceed with copying the folder.\n            destination_path = os.path.join(OUTPUT_DIRECTORY, category, new_subfolder_name)\n            \n            print(f\"Copying: '{original_folder_name}'  ->  '{category}/{new_subfolder_name}'\")\n            \n            try:\n                shutil.copytree(source_path, destination_path)\n                processed_count += 1\n            except FileExistsError:\n                print(f\"    - Skipped: Destination folder already exists.\")\n            except Exception as e:\n                print(f\"    - ❌ Error copying '{original_folder_name}': {e}\")\n        # If the category is not 'Tomato' or 'Potato', the script simply ignores it\n        # and moves to the next folder.\n            \n    print(f\"\\n✅ Done! Processed and copied {processed_count} folders related to {CLASSES_TO_PROCESS}.\")\n    print(f\"Your new, organized dataset is ready in the '{OUTPUT_DIRECTORY}' folder.\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:19:55.565632Z","iopub.execute_input":"2025-10-28T09:19:55.565854Z","iopub.status.idle":"2025-10-28T09:21:14.636409Z","shell.execute_reply.started":"2025-10-28T09:19:55.565832Z","shell.execute_reply":"2025-10-28T09:21:14.635794Z"}},"outputs":[{"name":"stdout","text":"Preparing to organize folders for ['Tomato', 'Potato']...\nSource: '/kaggle/input/combined-dataset1to4-modified/Combined_Dataset1to4'\nFound 74 total folders to check.\nCopying: 'Tomato___Late_blight'  ->  'Tomato/Late blight'\nCopying: 'Tomato___healthy'  ->  'Tomato/Healthy'\nCopying: 'Tomato___Spider_mites_Two-spotted_spider_mite'  ->  'Tomato/Spider mites two-spotted spider mite'\nCopying: 'Potato_Late_blight'  ->  'Potato/Late blight'\nCopying: 'Tomato___Early_blight'  ->  'Tomato/Early blight'\nCopying: 'Tomato___Septoria_leaf_spot'  ->  'Tomato/Septoria leaf spot'\nCopying: 'Potato_healthy'  ->  'Potato/Healthy'\nCopying: 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'  ->  'Tomato/Yellow leaf curl virus'\nCopying: 'Tomato___Bacterial_spot'  ->  'Tomato/Bacterial spot'\nCopying: 'Tomato___Target_Spot'  ->  'Tomato/Target spot'\nCopying: 'Potato_Early_blight'  ->  'Potato/Early blight'\nCopying: 'Tomato___Tomato_mosaic_virus'  ->  'Tomato/Mosaic virus'\nCopying: 'Tomato___Leaf_Mold'  ->  'Tomato/Leaf mold'\n\n✅ Done! Processed and copied 13 folders related to ['Tomato', 'Potato'].\nYour new, organized dataset is ready in the 'Organized_Dataset_Tomato_Potato' folder.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Create Stage 1 Splits (Plant Classification)","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\n# --- CONFIGURATION ---\n# The root directory of the previously organized dataset (Stage 0 output)\nSOURCE_ROOT = '/kaggle/working/Organized_Dataset_Tomato_Potato'\n# The root directory for the final Stage 1 (Coarse Classification) splits\nDESTINATION_ROOT = 'Stage_1_Splits'\n\n# Define the plant categories to process (must match the folder names in SOURCE_ROOT)\nPLANT_CATEGORIES = ['Tomato', 'Potato']\n\n# Define the desired split ratios (must sum to 1.0)\nSPLIT_RATIOS = {\n    'train': 0.70,\n    'validation': 0.15,\n    'test': 0.15\n}\n\ndef split_data():\n    \"\"\"\n    Combines all disease images per plant, shuffles them, and splits them\n    into the final train, validation, and test directories for Stage 1.\n    \"\"\"\n    if sum(SPLIT_RATIOS.values()) != 1.0:\n        print(\"❌ Error: Split ratios must sum exactly to 1.0. Check your configuration.\")\n        return\n\n    print(f\"Starting data split process for Stage 1 (Train: {SPLIT_RATIOS['train']:.0%}, Valid: {SPLIT_RATIOS['validation']:.0%}, Test: {SPLIT_RATIOS['test']:.0%})\")\n\n    # 1. Create the necessary destination directories\n    for split_type in SPLIT_RATIOS.keys():\n        for category in PLANT_CATEGORIES:\n            os.makedirs(os.path.join(DESTINATION_ROOT, split_type, category), exist_ok=True)\n\n    total_images_processed = 0\n\n    # 2. Process each plant category\n    for category in PLANT_CATEGORIES:\n        source_category_path = os.path.join(SOURCE_ROOT, category)\n\n        if not os.path.exists(source_category_path):\n            print(f\"⚠️ Warning: Source folder not found for {category} at {source_category_path}. Skipping.\")\n            continue\n\n        print(f\"\\n--- Processing {category} ---\")\n\n        # Collect all image file paths across all disease subfolders\n        all_image_paths = []\n        for root, _, files in os.walk(source_category_path):\n            for file in files:\n                # Basic check to ensure we only process image files\n                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    all_image_paths.append(os.path.join(root, file))\n\n        # 3. Shuffle and split the paths\n        random.shuffle(all_image_paths)\n        total_count = len(all_image_paths)\n        print(f\"Total images found: {total_count}\")\n\n        if total_count == 0:\n             print(f\"Skipping {category}: No images found.\")\n             continue\n\n        # Calculate split indices\n        train_end = int(total_count * SPLIT_RATIOS['train'])\n        validation_end = train_end + int(total_count * SPLIT_RATIOS['validation'])\n\n        # Split the list\n        train_files = all_image_paths[:train_end]\n        validation_files = all_image_paths[train_end:validation_end]\n        # Test takes the remainder to ensure all files are used\n        test_files = all_image_paths[validation_end:] \n\n        # Store files to copy by split type\n        split_files = {\n            'train': train_files,\n            'validation': validation_files,\n            'test': test_files\n        }\n\n        # 4. Copy files to the final destination structure\n        for split_type, file_list in split_files.items():\n            destination_dir = os.path.join(DESTINATION_ROOT, split_type, category)\n            print(f\"  - Copying {len(file_list):5d} files to {split_type}/{category}...\")\n\n            for src_path in file_list:\n                # Use os.path.basename to get only the filename (flattening the disease structure)\n                dst_path = os.path.join(destination_dir, os.path.basename(src_path))\n                try:\n                    shutil.copy2(src_path, dst_path) # copy2 preserves metadata\n                    total_images_processed += 1\n                except Exception as e:\n                     print(f\"    - ❌ Error copying {os.path.basename(src_path)}: {e}\")\n\n\n    print(f\"\\n✅ Data splitting complete. Total images copied: {total_images_processed}\")\n    print(f\"The Stage 1 dataset is ready in the '{DESTINATION_ROOT}' folder.\")\n\nif __name__ == \"__main__\":\n    split_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:21:19.793776Z","iopub.execute_input":"2025-10-28T09:21:19.794491Z","iopub.status.idle":"2025-10-28T09:21:22.402842Z","shell.execute_reply.started":"2025-10-28T09:21:19.794464Z","shell.execute_reply":"2025-10-28T09:21:22.402253Z"}},"outputs":[{"name":"stdout","text":"Starting data split process for Stage 1 (Train: 70%, Valid: 15%, Test: 15%)\n\n--- Processing Tomato ---\nTotal images found: 19006\n  - Copying 13304 files to train/Tomato...\n  - Copying  2850 files to validation/Tomato...\n  - Copying  2852 files to test/Tomato...\n\n--- Processing Potato ---\nTotal images found: 2344\n  - Copying  1640 files to train/Potato...\n  - Copying   351 files to validation/Potato...\n  - Copying   353 files to test/Potato...\n\n✅ Data splitting complete. Total images copied: 21350\nThe Stage 1 dataset is ready in the 'Stage_1_Splits' folder.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Create Stage 2 Splits (Disease Classification)","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\n# --- CONFIGURATION ---\n# SOURCE_ROOT: Source Directory, which is the output from the initial organization script\nSOURCE_ROOT = '/kaggle/working/Organized_Dataset_Tomato_Potato'\n# DESTINATION_ROOT: Destination Directory for the final Stage 2 split dataset\nDESTINATION_ROOT = 'Stage_2_Splits'\n\n# Plant Categories to process (must match the top-level folders in SOURCE_ROOT)\nPLANT_CATEGORIES = ['Tomato', 'Potato']\n\n# Desired split ratios: Train / Validation / Test (must sum to 1.0)\nSPLIT_RATIOS = {\n    'train': 0.70,\n    'validation': 0.15,\n    'test': 0.15\n}\n\ndef split_disease_data():\n    \"\"\"\n    For each plant category, this script divides the data by disease into separate\n    train, validation, and test directories. This prepares the dataset for\n    the specialized Stage 2 models.\n    \"\"\"\n    if sum(SPLIT_RATIOS.values()) != 1.0:\n        print(\"❌ Error: Split ratios must sum exactly to 1.0. Please check the configuration.\")\n        return\n\n    print(f\"Starting data split process for Stage 2 (Train: {SPLIT_RATIOS['train']:.0%}, Validation: {SPLIT_RATIOS['validation']:.0%}, Test: {SPLIT_RATIOS['test']:.0%})\")\n\n    total_images_processed = 0\n\n    # 1. Loop through each plant category (e.g., 'Tomato', 'Potato')\n    for category in PLANT_CATEGORIES:\n        source_category_path = os.path.join(SOURCE_ROOT, category)\n\n        if not os.path.exists(source_category_path):\n            print(f\"⚠️ Warning: Source folder not found for {category} at {source_category_path}. Skipping.\")\n            continue\n\n        print(f\"\\n--- Processing {category} ---\")\n\n        # 2. Identify disease subfolders (which serve as the specific labels)\n        disease_folders = [d for d in os.listdir(source_category_path)\n                           if os.path.isdir(os.path.join(source_category_path, d))]\n\n        if not disease_folders:\n            print(f\"  - No disease subfolders found for {category}. Skipping.\")\n            continue\n\n        for disease_name in disease_folders:\n            source_disease_path = os.path.join(source_category_path, disease_name)\n\n            # 3. Collect all image file paths for this disease\n            all_image_paths = [os.path.join(source_disease_path, f)\n                               for f in os.listdir(source_disease_path)\n                               if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n            random.shuffle(all_image_paths)\n            total_count = len(all_image_paths)\n\n            if total_count == 0:\n                 print(f\"  - No images found for disease '{disease_name}'. Skipping.\")\n                 continue\n\n            print(f\"  - Disease '{disease_name}': Total {total_count} images.\")\n\n            # 4. Calculate Split Indices\n            train_end = int(total_count * SPLIT_RATIOS['train'])\n            validation_end = train_end + int(total_count * SPLIT_RATIOS['validation'])\n\n            train_files = all_image_paths[:train_end]\n            validation_files = all_image_paths[train_end:validation_end]\n             # Test takes the remainder to ensure all files are used\n            test_files = all_image_paths[validation_end:]\n\n            split_files = {\n                'train': train_files,\n                'validation': validation_files,\n                'test': test_files\n            }\n\n            # 5. Copy files to the destination structure\n            for split_type, file_list in split_files.items():\n                # Destination Path: DESTINATION_ROOT / PLANT / SPLIT_TYPE / DISEASE\n                destination_dir = os.path.join(DESTINATION_ROOT, category, split_type, disease_name)\n                os.makedirs(destination_dir, exist_ok=True)\n\n                print(f\"    - Copying {len(file_list):4d} images to {split_type}/{disease_name}...\")\n\n                for src_path in file_list:\n                    dst_path = os.path.join(destination_dir, os.path.basename(src_path))\n                    try:\n                        shutil.copy2(src_path, dst_path)\n                        total_images_processed += 1\n                    except Exception as e:\n                        print(f\"      - ❌ Error copying {os.path.basename(src_path)}: {e}\")\n\n\n    print(f\"\\n✅ Data splitting complete. Total images copied: {total_images_processed}\")\n    print(f\"The Stage 2 dataset is ready in the '{DESTINATION_ROOT}' folder.\")\n\nif __name__ == \"__main__\":\n    split_disease_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:21:24.835819Z","iopub.execute_input":"2025-10-28T09:21:24.836530Z","iopub.status.idle":"2025-10-28T09:21:27.393124Z","shell.execute_reply.started":"2025-10-28T09:21:24.836506Z","shell.execute_reply":"2025-10-28T09:21:27.392552Z"}},"outputs":[{"name":"stdout","text":"Starting data split process for Stage 2 (Train: 70%, Validation: 15%, Test: 15%)\n\n--- Processing Tomato ---\n  - Disease 'Leaf mold': Total 1061 images.\n    - Copying  742 images to train/Leaf mold...\n    - Copying  159 images to validation/Leaf mold...\n    - Copying  160 images to test/Leaf mold...\n  - Disease 'Target spot': Total 1422 images.\n    - Copying  995 images to train/Target spot...\n    - Copying  213 images to validation/Target spot...\n    - Copying  214 images to test/Target spot...\n  - Disease 'Bacterial spot': Total 2234 images.\n    - Copying 1563 images to train/Bacterial spot...\n    - Copying  335 images to validation/Bacterial spot...\n    - Copying  336 images to test/Bacterial spot...\n  - Disease 'Mosaic virus': Total 452 images.\n    - Copying  316 images to train/Mosaic virus...\n    - Copying   67 images to validation/Mosaic virus...\n    - Copying   69 images to test/Mosaic virus...\n  - Disease 'Yellow leaf curl virus': Total 5423 images.\n    - Copying 3796 images to train/Yellow leaf curl virus...\n    - Copying  813 images to validation/Yellow leaf curl virus...\n    - Copying  814 images to test/Yellow leaf curl virus...\n  - Disease 'Late blight': Total 2009 images.\n    - Copying 1406 images to train/Late blight...\n    - Copying  301 images to validation/Late blight...\n    - Copying  302 images to test/Late blight...\n  - Disease 'Spider mites two-spotted spider mite': Total 1676 images.\n    - Copying 1173 images to train/Spider mites two-spotted spider mite...\n    - Copying  251 images to validation/Spider mites two-spotted spider mite...\n    - Copying  252 images to test/Spider mites two-spotted spider mite...\n  - Disease 'Early blight': Total 1105 images.\n    - Copying  773 images to train/Early blight...\n    - Copying  165 images to validation/Early blight...\n    - Copying  167 images to test/Early blight...\n  - Disease 'Healthy': Total 1684 images.\n    - Copying 1178 images to train/Healthy...\n    - Copying  252 images to validation/Healthy...\n    - Copying  254 images to test/Healthy...\n  - Disease 'Septoria leaf spot': Total 1940 images.\n    - Copying 1358 images to train/Septoria leaf spot...\n    - Copying  291 images to validation/Septoria leaf spot...\n    - Copying  291 images to test/Septoria leaf spot...\n\n--- Processing Potato ---\n  - Disease 'Late blight': Total 1095 images.\n    - Copying  766 images to train/Late blight...\n    - Copying  164 images to validation/Late blight...\n    - Copying  165 images to test/Late blight...\n  - Disease 'Early blight': Total 1097 images.\n    - Copying  767 images to train/Early blight...\n    - Copying  164 images to validation/Early blight...\n    - Copying  166 images to test/Early blight...\n  - Disease 'Healthy': Total 152 images.\n    - Copying  106 images to train/Healthy...\n    - Copying   22 images to validation/Healthy...\n    - Copying   24 images to test/Healthy...\n\n✅ Data splitting complete. Total images copied: 21350\nThe Stage 2 dataset is ready in the 'Stage_2_Splits' folder.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -U transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:21:30.666205Z","iopub.execute_input":"2025-10-28T09:21:30.666873Z","iopub.status.idle":"2025-10-28T09:21:45.850981Z","shell.execute_reply.started":"2025-10-28T09:21:30.666851Z","shell.execute_reply":"2025-10-28T09:21:45.850271Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nCollecting transformers\n  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\nCollecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.36.0 tokenizers-0.22.1 transformers-4.57.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(new_session=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:21:55.652068Z","iopub.execute_input":"2025-10-28T09:21:55.652608Z","iopub.status.idle":"2025-10-28T09:21:55.918393Z","shell.execute_reply.started":"2025-10-28T09:21:55.652580Z","shell.execute_reply":"2025-10-28T09:21:55.917598Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1ef40a37b5449e8a5bd40aa7686ecad"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoModel\nimport torch, torchvision.transforms as T\nfrom PIL import Image\nimport requests\n\nMODEL_ID = \"facebook/dinov3-convnext-base-pretrain-lvd1689m\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# load model\nmodel = AutoModel.from_pretrained(MODEL_ID, trust_remote_code=True).to(DEVICE).eval()\n\n# preprocessing\ntransform = T.Compose([\n    T.Resize(256),\n    T.CenterCrop(224),\n    T.ToTensor(),\n    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n])\n\n# test image\nurl = \"https://huggingface.co/datasets/mishig/sample_images/resolve/main/tiger.jpg\"\nimg = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\nx = transform(img).unsqueeze(0).to(DEVICE)\n\nwith torch.no_grad():\n    out = model(pixel_values=x)\n\nprint(\"CLS embedding:\", out.last_hidden_state[:,0,:].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:22:03.557373Z","iopub.execute_input":"2025-10-28T09:22:03.557883Z","iopub.status.idle":"2025-10-28T09:22:30.233624Z","shell.execute_reply.started":"2025-10-28T09:22:03.557858Z","shell.execute_reply":"2025-10-28T09:22:30.232938Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/449 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05d8ab704f87492bb9023f58f25090d1"}},"metadata":{}},{"name":"stderr","text":"2025-10-28 09:22:14.469303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761643334.666729      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761643334.727652      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/350M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287fd9a89a61456aabcce60632c52dcb"}},"metadata":{}},{"name":"stdout","text":"CLS embedding: torch.Size([1, 1024])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# STAGE 1 TRAINING","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np, json, torch\nfrom PIL import Image\nimport torchvision.transforms as T\nfrom transformers import AutoModel\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom tqdm.auto import tqdm\n\n# -------- CONFIG: adjust if needed --------\nSPLIT_ROOT = Path(\"/kaggle/working/Stage_1_Splits\")\nOUT = Path(\"/kaggle/working/embeddings\"); OUT.mkdir(parents=True, exist_ok=True)\nBATCH_SIZE = 8\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nMODEL_ID = \"facebook/dinov3-convnext-base-pretrain-lvd1689m\"\nIMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n# ------------------------------------------\n\n# HF auth (must have HF_TOKEN in Kaggle Secrets)\ntry:\n    hf_token = UserSecretsClient().get_secret(\"HF_TOKEN\")\n    login(token=hf_token, new_session=False)\nexcept:\n    print(\"HF_TOKEN not found in Kaggle Secrets. Proceeding without login, which might fail for some models.\")\n    hf_token=None\n\n# load model\nmodel = AutoModel.from_pretrained(MODEL_ID, trust_remote_code=True, token=hf_token).to(DEVICE).eval()\n\ntransform = T.Compose([\n    T.Resize(256),\n    T.CenterCrop(224),\n    T.ToTensor(),\n    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n])\n\n# Collect class list from the 'train' subdirectory\ntrain_dir = SPLIT_ROOT / \"train\"\nif not train_dir.exists():\n    raise SystemExit(f\"The directory {train_dir} does not exist. Please check your file structure.\")\n\n# --- MODIFICATION START ---\n# Original line that finds all folders:\n# classes = sorted([p.name for p in train_dir.iterdir() if p.is_dir()])\n\n# New line to only use specific folders:\nclasses = [\"Potato\", \"Tomato\"]\n# --- MODIFICATION END ---\n\nif not classes:\n    raise SystemExit(f\"No class folders found in {train_dir}. Expected structure: {SPLIT_ROOT}/train/<CLASS>\")\n\ncls2idx = {c:i for i,c in enumerate(classes)}\nprint(\"Processing only these classes:\", len(classes), classes)\n\ndef collect_from_split(split_root, split_name):\n    \"\"\"Return (paths, labels) for the given split.\n       Expects structure: split_root/<split_name>/<CLASS>/*.jpg\n    \"\"\"\n    paths, labels = [], []\n    split_folder = split_root / split_name\n    if not split_folder.exists() or not split_folder.is_dir():\n        return paths, np.array(labels, dtype=np.int32)\n\n    for c in classes:\n        class_folder = split_folder / c\n        if not class_folder.exists() or not class_folder.is_dir():\n            continue\n        for f in sorted(class_folder.iterdir()):\n            if f.is_file() and f.suffix.lower() in IMAGE_EXTS:\n                paths.append(str(f))\n                labels.append(cls2idx[c])\n    return paths, np.array(labels, dtype=np.int32)\n\ntrain_paths, y_train = collect_from_split(SPLIT_ROOT, \"train\")\nval_paths,   y_val   = collect_from_split(SPLIT_ROOT, \"validation\")\ntest_paths,  y_test  = collect_from_split(SPLIT_ROOT, \"test\")\n\nprint(f\"Images — train: {len(train_paths)}, val: {len(val_paths)}, test: {len(test_paths)}\")\n\ndef batch_embed(paths, batch_size=BATCH_SIZE):\n    embs = []\n    model.eval()\n    for i in tqdm(range(0, len(paths), batch_size), desc=\"Embedding batches\"):\n        batch = paths[i:i+batch_size]\n        imgs = []\n        for p in batch:\n            try:\n                imgs.append(transform(Image.open(p).convert(\"RGB\")))\n            except Exception as e:\n                print(\"skip:\", p, \"err:\", e)\n        if not imgs:\n            continue\n        x = torch.stack(imgs).to(DEVICE)\n        with torch.no_grad():\n            out = model(pixel_values=x)\n        embs.append(out.last_hidden_state[:,0,:].cpu().numpy())\n    return np.vstack(embs) if embs else np.zeros((0,0), dtype=np.float32)\n\n# Create embeddings if they don't exist\nif (OUT/\"X_train.npy\").exists() and (OUT/\"X_val.npy\").exists() and (OUT/\"X_test.npy\").exists():\n    print(\"Embeddings already exist — loading.\")\n    X_train = np.load(OUT/\"X_train.npy\"); y_train = np.load(OUT/\"y_train.npy\")\n    X_val   = np.load(OUT/\"X_val.npy\");   y_val   = np.load(OUT/\"y_val.npy\")\n    X_test  = np.load(OUT/\"X_test.npy\");  y_test  = np.load(OUT/\"y_test.npy\")\nelse:\n    print(\"Extracting train embeddings...\")\n    X_train = batch_embed(train_paths)\n    np.save(OUT/\"X_train.npy\", X_train); np.save(OUT/\"y_train.npy\", y_train)\n    print(\"Saved X_train\", X_train.shape)\n\n    print(\"Extracting val embeddings...\")\n    X_val = batch_embed(val_paths)\n    np.save(OUT/\"X_val.npy\", X_val); np.save(OUT/\"y_val.npy\", y_val)\n    print(\"Saved X_val\", X_val.shape)\n\n    print(\"Extracting test embeddings...\")\n    X_test = batch_embed(test_paths)\n    np.save(OUT/\"X_test.npy\", X_test); np.save(OUT/\"y_test.npy\", y_test)\n    print(\"Saved X_test\", X_test.shape)\n\nprint(\"Done. Shapes:\", np.load(OUT/\"X_train.npy\").shape, np.load(OUT/\"X_val.npy\").shape, np.load(OUT/\"X_test.npy\").shape)\nprint(\"Embeddings saved to:\", OUT.resolve())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:22:39.102770Z","iopub.execute_input":"2025-10-28T09:22:39.103303Z","iopub.status.idle":"2025-10-28T09:27:29.418641Z","shell.execute_reply.started":"2025-10-28T09:22:39.103280Z","shell.execute_reply":"2025-10-28T09:27:29.417975Z"}},"outputs":[{"name":"stdout","text":"Processing only these classes: 2 ['Potato', 'Tomato']\nImages — train: 14938, val: 3201, test: 3205\nExtracting train embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding batches:   0%|          | 0/1868 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea5bef7b1e6b46c5a06eb4ac19024c12"}},"metadata":{}},{"name":"stdout","text":"Saved X_train (14938, 1024)\nExtracting val embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding batches:   0%|          | 0/401 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3de8bfa59bd84055bf361fde5e071c51"}},"metadata":{}},{"name":"stdout","text":"Saved X_val (3201, 1024)\nExtracting test embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding batches:   0%|          | 0/401 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe92ca35535b44e89bc00046d51c443f"}},"metadata":{}},{"name":"stdout","text":"Saved X_test (3205, 1024)\nDone. Shapes: (14938, 1024) (3201, 1024) (3205, 1024)\nEmbeddings saved to: /kaggle/working/embeddings\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, normalize\nimport joblib\nimport os\n\nEMB_DIR = \"/kaggle/working/embeddings\"\nMODEL_OUT = os.path.join(EMB_DIR, \"stage1_classifier_model.joblib\")\n\n\n# load\nX_train = np.load(os.path.join(EMB_DIR, \"X_train.npy\"))\ny_train = np.load(os.path.join(EMB_DIR, \"y_train.npy\"))\nX_val   = np.load(os.path.join(EMB_DIR, \"X_val.npy\"))\ny_val   = np.load(os.path.join(EMB_DIR, \"y_val.npy\"))\n\nprint(\"Shapes loaded — X_train:\", X_train.shape, \"y_train:\", y_train.shape, \"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n\n# basic sanity\nif X_train.size == 0 or X_val.size == 0:\n    raise SystemExit(\"Empty embeddings — check previous step. Exiting.\")\n\nif X_train.shape[0] != y_train.shape[0] or X_val.shape[0] != y_val.shape[0]:\n    raise SystemExit(\"Mismatch between number of embeddings and labels. Exiting.\")\n\n# Option A: Standardize (common). with_mean=True normally okay unless huge memmap / sparse\nsc = StandardScaler(with_mean=True, with_std=True)\nX_train_s = sc.fit_transform(X_train)\nX_val_s   = sc.transform(X_val)\n\n# Option B (alternative, often good for cosine-like): L2 normalize\n# X_train_s = normalize(X_train, norm='l2')\n# X_val_s   = normalize(X_val, norm='l2')\n\n# Train logistic regression (use class_weight='balanced' if classes imbalanced)\nclf = LogisticRegression(max_iter=2000, n_jobs=-1, C=1.0, class_weight=None, random_state=42)\nclf.fit(X_train_s, y_train)\n\n# Predict & evaluate\ny_pred = clf.predict(X_val_s)\nacc = accuracy_score(y_val, y_pred)\nprint(f\"Validation accuracy: {acc:.4f}\\n\")\nprint(\"Classification report:\\n\", classification_report(y_val, y_pred))\n\n# Save scaler + model\njoblib.dump((sc, clf), MODEL_OUT)\nprint(\"Saved model to:\", MODEL_OUT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:27:36.676553Z","iopub.execute_input":"2025-10-28T09:27:36.676822Z","iopub.status.idle":"2025-10-28T09:27:45.120712Z","shell.execute_reply.started":"2025-10-28T09:27:36.676803Z","shell.execute_reply":"2025-10-28T09:27:45.119984Z"}},"outputs":[{"name":"stdout","text":"Shapes loaded — X_train: (14938, 1024) y_train: (14938,) X_val: (3201, 1024) y_val: (3201,)\nValidation accuracy: 0.9916\n\nClassification report:\n               precision    recall  f1-score   support\n\n           0       0.97      0.95      0.96       351\n           1       0.99      1.00      1.00      2850\n\n    accuracy                           0.99      3201\n   macro avg       0.98      0.98      0.98      3201\nweighted avg       0.99      0.99      0.99      3201\n\nSaved model to: /kaggle/working/embeddings/stage1_classifier_model.joblib\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# STAGE 2 TOMATO ","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np, torch\nfrom PIL import Image\nimport torchvision.transforms as T\nfrom transformers import AutoModel\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom tqdm.auto import tqdm\n\n# -------- CONFIG --------\nSPLIT_ROOT = Path(\"/kaggle/working/Stage_2_Splits/Tomato\")\nOUT = Path(\"/kaggle/working/embeddings_tomato\"); OUT.mkdir(parents=True, exist_ok=True)\nBATCH_SIZE = 8\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nMODEL_ID = \"facebook/dinov3-convnext-base-pretrain-lvd1689m\"\nIMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n# -------------------------\n\n# Hugging Face auth\ntry:\n    hf_token = UserSecretsClient().get_secret(\"HF_TOKEN\")\n    login(token=hf_token, new_session=False)\nexcept:\n    print(\"HF_TOKEN not found in Kaggle Secrets — proceeding without it.\")\n    hf_token = None\n\n# Load pretrained DINOv2 model\nmodel = AutoModel.from_pretrained(MODEL_ID, trust_remote_code=True, token=hf_token).to(DEVICE).eval()\n\n# Image transform\ntransform = T.Compose([\n    T.Resize(256),\n    T.CenterCrop(224),\n    T.ToTensor(),\n    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n])\n\n# ---------------------------------------------------------------\n# Collect class folders under Tomato/train\n# ---------------------------------------------------------------\ntrain_dir = SPLIT_ROOT / \"train\"\nif not train_dir.exists():\n    raise SystemExit(f\"The directory {train_dir} does not exist.\")\n\nclasses = sorted([p.name for p in train_dir.iterdir() if p.is_dir()])\nif not classes:\n    raise SystemExit(\"No disease folders found inside Tomato/train.\")\n\ncls2idx = {c:i for i,c in enumerate(classes)}\nprint(f\"Found {len(classes)} Tomato disease classes:\\n\", classes)\n\n# ---------------------------------------------------------------\n# Collect image paths and labels for each split\n# ---------------------------------------------------------------\ndef collect_from_split(split_root, split_name):\n    paths, labels = [], []\n    split_folder = split_root / split_name\n    if not split_folder.exists():\n        return paths, np.array(labels, dtype=np.int32)\n\n    for c in classes:\n        class_folder = split_folder / c\n        if not class_folder.exists():\n            continue\n        for f in sorted(class_folder.iterdir()):\n            if f.is_file() and f.suffix.lower() in IMAGE_EXTS:\n                paths.append(str(f))\n                labels.append(cls2idx[c])\n    return paths, np.array(labels, dtype=np.int32)\n\ntrain_paths, y_train = collect_from_split(SPLIT_ROOT, \"train\")\nval_paths,   y_val   = collect_from_split(SPLIT_ROOT, \"validation\")\ntest_paths,  y_test  = collect_from_split(SPLIT_ROOT, \"test\")\n\nprint(f\"Images — train: {len(train_paths)}, val: {len(val_paths)}, test: {len(test_paths)}\")\n\n# ---------------------------------------------------------------\n# Embedding extraction\n# ---------------------------------------------------------------\ndef batch_embed(paths, batch_size=BATCH_SIZE):\n    embs = []\n    model.eval()\n    for i in tqdm(range(0, len(paths), batch_size), desc=\"Embedding batches\"):\n        batch = paths[i:i+batch_size]\n        imgs = []\n        for p in batch:\n            try:\n                imgs.append(transform(Image.open(p).convert(\"RGB\")))\n            except Exception as e:\n                print(\"skip:\", p, \"err:\", e)\n        if not imgs:\n            continue\n        x = torch.stack(imgs).to(DEVICE)\n        with torch.no_grad():\n            out = model(pixel_values=x)\n        embs.append(out.last_hidden_state[:,0,:].cpu().numpy())\n    return np.vstack(embs) if embs else np.zeros((0,0), dtype=np.float32)\n\n# ---------------------------------------------------------------\n# Save embeddings\n# ---------------------------------------------------------------\nif (OUT/\"X_train.npy\").exists():\n    print(\"Embeddings already exist — loading.\")\n    X_train = np.load(OUT/\"X_train.npy\"); y_train = np.load(OUT/\"y_train.npy\")\n    X_val   = np.load(OUT/\"X_val.npy\");   y_val   = np.load(OUT/\"y_val.npy\")\n    X_test  = np.load(OUT/\"X_test.npy\");  y_test  = np.load(OUT/\"y_test.npy\")\nelse:\n    print(\"Extracting train embeddings...\")\n    X_train = batch_embed(train_paths)\n    np.save(OUT/\"X_train.npy\", X_train); np.save(OUT/\"y_train.npy\", y_train)\n    print(\"Saved X_train\", X_train.shape)\n\n    print(\"Extracting val embeddings...\")\n    X_val = batch_embed(val_paths)\n    np.save(OUT/\"X_val.npy\", X_val); np.save(OUT/\"y_val.npy\", y_val)\n    print(\"Saved X_val\", X_val.shape)\n\n    print(\"Extracting test embeddings...\")\n    X_test = batch_embed(test_paths)\n    np.save(OUT/\"X_test.npy\", X_test); np.save(OUT/\"y_test.npy\", y_test)\n    print(\"Saved X_test\", X_test.shape)\n\nprint(\"Done. Shapes:\")\nprint(\"  Train:\", np.load(OUT/'X_train.npy').shape)\nprint(\"  Val:  \", np.load(OUT/'X_val.npy').shape)\nprint(\"  Test: \", np.load(OUT/'X_test.npy').shape)\nprint(\"Tomato embeddings saved to:\", OUT.resolve())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:27:51.370966Z","iopub.execute_input":"2025-10-28T09:27:51.371235Z","iopub.status.idle":"2025-10-28T09:32:21.824471Z","shell.execute_reply.started":"2025-10-28T09:27:51.371214Z","shell.execute_reply":"2025-10-28T09:32:21.823664Z"}},"outputs":[{"name":"stdout","text":"Found 10 Tomato disease classes:\n ['Bacterial spot', 'Early blight', 'Healthy', 'Late blight', 'Leaf mold', 'Mosaic virus', 'Septoria leaf spot', 'Spider mites two-spotted spider mite', 'Target spot', 'Yellow leaf curl virus']\nImages — train: 13300, val: 2847, test: 2859\nExtracting train embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding batches:   0%|          | 0/1663 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1a2ccfc11624f3e8dced3af8d9dec17"}},"metadata":{}},{"name":"stdout","text":"Saved X_train (13300, 1024)\nExtracting val embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding batches:   0%|          | 0/356 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdf6853ff8bb40688ae6102b5fb75972"}},"metadata":{}},{"name":"stdout","text":"Saved X_val (2847, 1024)\nExtracting test embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding batches:   0%|          | 0/358 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e66eb46907944b0ba57a33fbb73d6be"}},"metadata":{}},{"name":"stdout","text":"Saved X_test (2859, 1024)\nDone. Shapes:\n  Train: (13300, 1024)\n  Val:   (2847, 1024)\n  Test:  (2859, 1024)\nTomato embeddings saved to: /kaggle/working/embeddings_tomato\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, normalize\nimport joblib\nimport os\n\nEMB_DIR = \"/kaggle/working/embeddings_tomato\"\nMODEL_OUT = os.path.join(EMB_DIR, \"stage2_classifier_model_tomato.joblib\")\n\n\n# load\nX_train = np.load(os.path.join(EMB_DIR, \"X_train.npy\"))\ny_train = np.load(os.path.join(EMB_DIR, \"y_train.npy\"))\nX_val   = np.load(os.path.join(EMB_DIR, \"X_val.npy\"))\ny_val   = np.load(os.path.join(EMB_DIR, \"y_val.npy\"))\n\nprint(\"Shapes loaded — X_train:\", X_train.shape, \"y_train:\", y_train.shape, \"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n\n# basic sanity\nif X_train.size == 0 or X_val.size == 0:\n    raise SystemExit(\"Empty embeddings — check previous step. Exiting.\")\n\nif X_train.shape[0] != y_train.shape[0] or X_val.shape[0] != y_val.shape[0]:\n    raise SystemExit(\"Mismatch between number of embeddings and labels. Exiting.\")\n\n# Option A: Standardize (common). with_mean=True normally okay unless huge memmap / sparse\nsc = StandardScaler(with_mean=True, with_std=True)\nX_train_s = sc.fit_transform(X_train)\nX_val_s   = sc.transform(X_val)\n\n# Option B (alternative, often good for cosine-like): L2 normalize\n# X_train_s = normalize(X_train, norm='l2')\n# X_val_s   = normalize(X_val, norm='l2')\n\n# Train logistic regression (use class_weight='balanced' if classes imbalanced)\nclf = LogisticRegression(max_iter=2000, n_jobs=-1, C=1.0, class_weight=None, random_state=42)\nclf.fit(X_train_s, y_train)\n\n# Predict & evaluate\ny_pred = clf.predict(X_val_s)\nacc = accuracy_score(y_val, y_pred)\nprint(f\"Validation accuracy: {acc:.4f}\\n\")\nprint(\"Classification report:\\n\", classification_report(y_val, y_pred))\n\n# Save scaler + model\njoblib.dump((sc, clf), MODEL_OUT)\nprint(\"Saved model to:\", MODEL_OUT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:32:26.688387Z","iopub.execute_input":"2025-10-28T09:32:26.689050Z","iopub.status.idle":"2025-10-28T09:33:28.959857Z","shell.execute_reply.started":"2025-10-28T09:32:26.689024Z","shell.execute_reply":"2025-10-28T09:33:28.959110Z"}},"outputs":[{"name":"stdout","text":"Shapes loaded — X_train: (13300, 1024) y_train: (13300,) X_val: (2847, 1024) y_val: (2847,)\nValidation accuracy: 0.9456\n\nClassification report:\n               precision    recall  f1-score   support\n\n           0       0.93      0.92      0.92       335\n           1       0.83      0.83      0.83       165\n           2       0.96      0.96      0.96       252\n           3       0.93      0.92      0.93       301\n           4       0.91      0.94      0.93       159\n           5       0.94      0.88      0.91        67\n           6       0.94      0.94      0.94       291\n           7       0.94      0.96      0.95       251\n           8       0.94      0.93      0.94       213\n           9       0.99      0.99      0.99       813\n\n    accuracy                           0.95      2847\n   macro avg       0.93      0.93      0.93      2847\nweighted avg       0.95      0.95      0.95      2847\n\nSaved model to: /kaggle/working/embeddings_tomato/stage2_classifier_model_tomato.joblib\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# STAGE 2 POTATO","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np, torch\nfrom PIL import Image\nimport torchvision.transforms as T\nfrom transformers import AutoModel\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom tqdm.auto import tqdm\n\n# -------- CONFIG --------\nSPLIT_ROOT = Path(\"/kaggle/working/Stage_2_Splits/Potato\")\nOUT = Path(\"/kaggle/working/embeddings_potato\"); OUT.mkdir(parents=True, exist_ok=True)\nBATCH_SIZE = 8\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nMODEL_ID = \"facebook/dinov3-convnext-base-pretrain-lvd1689m\"\nIMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n# -------------------------\n\n# Hugging Face auth\ntry:\n    hf_token = UserSecretsClient().get_secret(\"HF_TOKEN\")\n    login(token=hf_token, new_session=False)\nexcept:\n    print(\"HF_TOKEN not found in Kaggle Secrets — proceeding without it.\")\n    hf_token = None\n\n# Load pretrained DINOv2 model\nmodel = AutoModel.from_pretrained(MODEL_ID, trust_remote_code=True, token=hf_token).to(DEVICE).eval()\n\n# Image transform\ntransform = T.Compose([\n    T.Resize(256),\n    T.CenterCrop(224),\n    T.ToTensor(),\n    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n])\n\n# ---------------------------------------------------------------\n# Collect class folders under Potato/train\n# ---------------------------------------------------------------\ntrain_dir = SPLIT_ROOT / \"train\"\nif not train_dir.exists():\n    raise SystemExit(f\"The directory {train_dir} does not exist.\")\n\nclasses = sorted([p.name for p in train_dir.iterdir() if p.is_dir()])\nif not classes:\n    raise SystemExit(\"No disease folders found inside Potato/train.\")\n\ncls2idx = {c:i for i,c in enumerate(classes)}\nprint(f\"Found {len(classes)} Potato disease classes:\\n\", classes)\n\n# ---------------------------------------------------------------\n# Collect image paths and labels for each split\n# ---------------------------------------------------------------\ndef collect_from_split(split_root, split_name):\n    paths, labels = [], []\n    split_folder = split_root / split_name\n    if not split_folder.exists():\n        return paths, np.array(labels, dtype=np.int32)\n\n    for c in classes:\n        class_folder = split_folder / c\n        if not class_folder.exists():\n            continue\n        for f in sorted(class_folder.iterdir()):\n            if f.is_file() and f.suffix.lower() in IMAGE_EXTS:\n                paths.append(str(f))\n                labels.append(cls2idx[c])\n    return paths, np.array(labels, dtype=np.int32)\n\ntrain_paths, y_train = collect_from_split(SPLIT_ROOT, \"train\")\nval_paths,   y_val   = collect_from_split(SPLIT_ROOT, \"validation\")\ntest_paths,  y_test  = collect_from_split(SPLIT_ROOT, \"test\")\n\nprint(f\"Images — train: {len(train_paths)}, val: {len(val_paths)}, test: {len(test_paths)}\")\n\n# ---------------------------------------------------------------\n# Embedding extraction\n# ---------------------------------------------------------------\ndef batch_embed(paths, batch_size=BATCH_SIZE):\n    embs = []\n    model.eval()\n    for i in tqdm(range(0, len(paths), batch_size), desc=\"Embedding batches\"):\n        batch = paths[i:i+batch_size]\n        imgs = []\n        for p in batch:\n            try:\n                imgs.append(transform(Image.open(p).convert(\"RGB\")))\n            except Exception as e:\n                print(\"skip:\", p, \"err:\", e)\n        if not imgs:\n            continue\n        x = torch.stack(imgs).to(DEVICE)\n        with torch.no_grad():\n            out = model(pixel_values=x)\n        embs.append(out.last_hidden_state[:,0,:].cpu().numpy())\n    return np.vstack(embs) if embs else np.zeros((0,0), dtype=np.float32)\n\n# ---------------------------------------------------------------\n# Save embeddings\n# ---------------------------------------------------------------\nif (OUT/\"X_train.npy\").exists():\n    print(\"Embeddings already exist — loading.\")\n    X_train = np.load(OUT/\"X_train.npy\"); y_train = np.load(OUT/\"y_train.npy\")\n    X_val   = np.load(OUT/\"X_val.npy\");   y_val   = np.load(OUT/\"y_val.npy\")\n    X_test  = np.load(OUT/\"X_test.npy\");  y_test  = np.load(OUT/\"y_test.npy\")\nelse:\n    print(\"Extracting train embeddings...\")\n    X_train = batch_embed(train_paths)\n    np.save(OUT/\"X_train.npy\", X_train); np.save(OUT/\"y_train.npy\", y_train)\n    print(\"Saved X_train\", X_train.shape)\n\n    print(\"Extracting val embeddings...\")\n    X_val = batch_embed(val_paths)\n    np.save(OUT/\"X_val.npy\", X_val); np.save(OUT/\"y_val.npy\", y_val)\n    print(\"Saved X_val\", X_val.shape)\n\n    print(\"Extracting test embeddings...\")\n    X_test = batch_embed(test_paths)\n    np.save(OUT/\"X_test.npy\", X_test); np.save(OUT/\"y_test.npy\", y_test)\n    print(\"Saved X_test\", X_test.shape)\n\nprint(\"Done. Shapes:\")\nprint(\"  Train:\", np.load(OUT/'X_train.npy').shape)\nprint(\"  Val:  \", np.load(OUT/'X_val.npy').shape)\nprint(\"  Test: \", np.load(OUT/'X_test.npy').shape)\nprint(\"Potato embeddings saved to:\", OUT.resolve())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:34:05.044242Z","iopub.execute_input":"2025-10-28T09:34:05.044856Z","iopub.status.idle":"2025-10-28T09:34:39.585357Z","shell.execute_reply.started":"2025-10-28T09:34:05.044824Z","shell.execute_reply":"2025-10-28T09:34:39.584607Z"}},"outputs":[{"name":"stdout","text":"Found 3 Potato disease classes:\n ['Early blight', 'Healthy', 'Late blight']\nImages — train: 1639, val: 350, test: 355\nExtracting train embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding batches:   0%|          | 0/205 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c677f42e9b842589fb458ee9f84be3d"}},"metadata":{}},{"name":"stdout","text":"Saved X_train (1639, 1024)\nExtracting val embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding batches:   0%|          | 0/44 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34ce9175d8e94bf4bc511d7dc44d0678"}},"metadata":{}},{"name":"stdout","text":"Saved X_val (350, 1024)\nExtracting test embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding batches:   0%|          | 0/45 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"464b8d2f4f1a47be96f3ab13141bfc2a"}},"metadata":{}},{"name":"stdout","text":"Saved X_test (355, 1024)\nDone. Shapes:\n  Train: (1639, 1024)\n  Val:   (350, 1024)\n  Test:  (355, 1024)\nPotato embeddings saved to: /kaggle/working/embeddings_potato\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, normalize\nimport joblib\nimport os\n\nEMB_DIR = \"/kaggle/working/embeddings_potato\"\nMODEL_OUT = os.path.join(EMB_DIR, \"stage2_classifier_model_potato.joblib\")\n\n\n# load\nX_train = np.load(os.path.join(EMB_DIR, \"X_train.npy\"))\ny_train = np.load(os.path.join(EMB_DIR, \"y_train.npy\"))\nX_val   = np.load(os.path.join(EMB_DIR, \"X_val.npy\"))\ny_val   = np.load(os.path.join(EMB_DIR, \"y_val.npy\"))\n\nprint(\"Shapes loaded — X_train:\", X_train.shape, \"y_train:\", y_train.shape, \"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n\n# basic sanity\nif X_train.size == 0 or X_val.size == 0:\n    raise SystemExit(\"Empty embeddings — check previous step. Exiting.\")\n\nif X_train.shape[0] != y_train.shape[0] or X_val.shape[0] != y_val.shape[0]:\n    raise SystemExit(\"Mismatch between number of embeddings and labels. Exiting.\")\n\n# Option A: Standardize (common). with_mean=True normally okay unless huge memmap / sparse\nsc = StandardScaler(with_mean=True, with_std=True)\nX_train_s = sc.fit_transform(X_train)\nX_val_s   = sc.transform(X_val)\n\n# Option B (alternative, often good for cosine-like): L2 normalize\n# X_train_s = normalize(X_train, norm='l2')\n# X_val_s   = normalize(X_val, norm='l2')\n\n# Train logistic regression (use class_weight='balanced' if classes imbalanced)\nclf = LogisticRegression(max_iter=2000, n_jobs=-1, C=1.0, class_weight=None, random_state=42)\nclf.fit(X_train_s, y_train)\n\n# Predict & evaluate\ny_pred = clf.predict(X_val_s)\nacc = accuracy_score(y_val, y_pred)\nprint(f\"Validation accuracy: {acc:.4f}\\n\")\nprint(\"Classification report:\\n\", classification_report(y_val, y_pred))\n\n# Save scaler + model\njoblib.dump((sc, clf), MODEL_OUT)\nprint(\"Saved model to:\", MODEL_OUT)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:34:45.374048Z","iopub.execute_input":"2025-10-28T09:34:45.374328Z","iopub.status.idle":"2025-10-28T09:34:47.917045Z","shell.execute_reply.started":"2025-10-28T09:34:45.374310Z","shell.execute_reply":"2025-10-28T09:34:47.916325Z"}},"outputs":[{"name":"stdout","text":"Shapes loaded — X_train: (1639, 1024) y_train: (1639,) X_val: (350, 1024) y_val: (350,)\nValidation accuracy: 0.9457\n\nClassification report:\n               precision    recall  f1-score   support\n\n           0       0.96      0.94      0.95       164\n           1       0.95      0.91      0.93        22\n           2       0.93      0.96      0.94       164\n\n    accuracy                           0.95       350\n   macro avg       0.95      0.94      0.94       350\nweighted avg       0.95      0.95      0.95       350\n\nSaved model to: /kaggle/working/embeddings_potato/stage2_classifier_model_potato.joblib\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# 2 STAGE INFERENCE PIPELINE","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport joblib\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score\n\n# ================== PATHS ==================\nSTAGE1_DIR = \"/kaggle/working/embeddings\"\nSTAGE2_TOMATO_DIR = \"/kaggle/working/embeddings_tomato\"\nSTAGE2_POTATO_DIR = \"/kaggle/working/embeddings_potato\"\n\nSTAGE1_MODEL_PATH = os.path.join(STAGE1_DIR, \"stage1_classifier_model.joblib\")\nSTAGE2_TOMATO_MODEL_PATH = os.path.join(STAGE2_TOMATO_DIR, \"stage2_classifier_model_tomato.joblib\")\nSTAGE2_POTATO_MODEL_PATH = os.path.join(STAGE2_POTATO_DIR, \"stage2_classifier_model_potato.joblib\")\n\nOUTPUT_CSV = \"/kaggle/working/final_inference_results.csv\"\n\n# ================== UTILS ==================\ndef load_model_safely(path):\n    \"\"\"Handles joblib files that may store scaler+model tuples or dicts.\"\"\"\n    obj = joblib.load(path)\n\n    # Case 1: tuple (scaler, model)\n    if isinstance(obj, tuple):\n        if len(obj) == 2 and hasattr(obj[1], \"predict\"):\n            return obj  # (scaler, model)\n        else:\n            return obj[0]\n\n    # Case 2: dict format\n    if isinstance(obj, dict):\n        if \"scaler\" in obj and \"model\" in obj:\n            return (obj[\"scaler\"], obj[\"model\"])\n        elif \"model\" in obj:\n            return obj[\"model\"]\n\n    # Case 3: direct model\n    return obj\n\n\ndef predict_with_optional_scaler(model_obj, X):\n    \"\"\"Applies scaler if available and returns predictions.\"\"\"\n    if isinstance(model_obj, tuple):\n        scaler, model = model_obj\n        X = scaler.transform(X)\n        return model.predict(X), model\n    else:\n        return model_obj.predict(X), model_obj\n\n\ndef predict_proba_with_optional_scaler(model_obj, X):\n    \"\"\"Predicts probabilities (for multi-class models).\"\"\"\n    if isinstance(model_obj, tuple):\n        scaler, model = model_obj\n        X = scaler.transform(X)\n        return model.predict_proba(X), model\n    else:\n        return model_obj.predict_proba(X), model_obj\n\n\n# ================== LOAD MODELS ==================\nprint(\" Loading trained models...\")\nstage1_model = load_model_safely(STAGE1_MODEL_PATH)\nstage2_tomato = load_model_safely(STAGE2_TOMATO_MODEL_PATH)\nstage2_potato = load_model_safely(STAGE2_POTATO_MODEL_PATH)\nprint(\"All models loaded successfully.\\n\")\n\n# ================== LOAD EMBEDDINGS ==================\nprint(\" Loading precomputed embeddings...\")\n\nX_stage1 = np.load(os.path.join(STAGE1_DIR, \"X_test.npy\"))\ny_stage1 = np.load(os.path.join(STAGE1_DIR, \"y_test.npy\"))\n\nX_tomato = np.load(os.path.join(STAGE2_TOMATO_DIR, \"X_test.npy\"))\ny_tomato = np.load(os.path.join(STAGE2_TOMATO_DIR, \"y_test.npy\"))\n\nX_potato = np.load(os.path.join(STAGE2_POTATO_DIR, \"X_test.npy\"))\ny_potato = np.load(os.path.join(STAGE2_POTATO_DIR, \"y_test.npy\"))\n\nprint(f\"Stage1 embeddings: {X_stage1.shape}\")\nprint(f\"Tomato embeddings: {X_tomato.shape}\")\nprint(f\"Potato embeddings: {X_potato.shape}\\n\")\n\n# ================== STAGE 1 INFERENCE ==================\nprint(\" Running Stage 1: Plant type classification...\")\nstage1_preds, stage1_clf = predict_with_optional_scaler(stage1_model, X_stage1)\nstage1_labels = np.array([\"Tomato\" if p == 1 else \"Potato\" for p in stage1_preds])\nstage1_acc = accuracy_score(y_stage1, stage1_preds)\nprint(f\"Stage 1 Accuracy: {stage1_acc*100:.2f}%\\n\")\n\n# ================== STAGE 2 INFERENCE ==================\nprint(\" Running Stage 2: Disease classification...\")\n\n# Tomato disease prediction\nprint(\" Predicting Tomato diseases...\")\ntomato_probs, tomato_clf = predict_proba_with_optional_scaler(stage2_tomato, X_tomato)\ntomato_preds = tomato_clf.classes_[np.argmax(tomato_probs, axis=1)]\ntomato_acc = accuracy_score(y_tomato, tomato_preds)\nprint(f\" Tomato Disease Accuracy: {tomato_acc*100:.2f}%\\n\")\n\n# Potato disease prediction\nprint(\" Predicting Potato diseases...\")\npotato_probs, potato_clf = predict_proba_with_optional_scaler(stage2_potato, X_potato)\npotato_preds = potato_clf.classes_[np.argmax(potato_probs, axis=1)]\npotato_acc = accuracy_score(y_potato, potato_preds)\nprint(f\" Potato Disease Accuracy: {potato_acc*100:.2f}%\\n\")\n\n# ================== SAVE RESULTS ==================\nprint(\"Saving predictions...\")\n\ndf_stage1 = pd.DataFrame({\n    \"true_plant\": y_stage1,\n    \"predicted_plant\": stage1_labels\n})\n\ndf_tomato = pd.DataFrame({\n    \"plant\": \"Tomato\",\n    \"true_disease\": y_tomato,\n    \"predicted_disease\": tomato_preds\n})\n\ndf_potato = pd.DataFrame({\n    \"plant\": \"Potato\",\n    \"true_disease\": y_potato,\n    \"predicted_disease\": potato_preds\n})\n\nfinal_df = pd.concat([df_stage1, df_tomato, df_potato], axis=0, ignore_index=True)\nfinal_df.to_csv(OUTPUT_CSV, index=False)\n\nprint(f\" All predictions saved to {OUTPUT_CSV}\")\nprint(f\"\\n Summary:\")\nprint(f\"Stage1 Accuracy: {stage1_acc*100:.2f}%\")\nprint(f\"Tomato Disease Accuracy: {tomato_acc*100:.2f}%\")\nprint(f\"Potato Disease Accuracy: {potato_acc*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T09:55:27.221322Z","iopub.execute_input":"2025-10-28T09:55:27.221891Z","iopub.status.idle":"2025-10-28T09:55:27.327271Z","shell.execute_reply.started":"2025-10-28T09:55:27.221860Z","shell.execute_reply":"2025-10-28T09:55:27.326627Z"}},"outputs":[{"name":"stdout","text":" Loading trained models...\nAll models loaded successfully.\n\n Loading precomputed embeddings...\nStage1 embeddings: (3205, 1024)\nTomato embeddings: (2859, 1024)\nPotato embeddings: (355, 1024)\n\n Running Stage 1: Plant type classification...\nStage 1 Accuracy: 99.16%\n\n Running Stage 2: Disease classification...\n Predicting Tomato diseases...\n Tomato Disease Accuracy: 95.21%\n\n Predicting Potato diseases...\n Potato Disease Accuracy: 96.34%\n\nSaving predictions...\n All predictions saved to /kaggle/working/final_inference_results.csv\n\n Summary:\nStage1 Accuracy: 99.16%\nTomato Disease Accuracy: 95.21%\nPotato Disease Accuracy: 96.34%\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport joblib\nfrom sklearn.metrics import accuracy_score\n\n# ---------------- CONFIG ----------------\nSTAGE1_DIR = \"/kaggle/working/embeddings\"\nSTAGE2_TOMATO_DIR = \"/kaggle/working/embeddings_tomato\"\nSTAGE2_POTATO_DIR = \"/kaggle/working/embeddings_potato\"\n\nSTAGE1_MODEL_PATH = os.path.join(STAGE1_DIR, \"stage1_classifier_model.joblib\")\nSTAGE2_TOMATO_MODEL_PATH = os.path.join(STAGE2_TOMATO_DIR, \"stage2_classifier_model_tomato.joblib\")\nSTAGE2_POTATO_MODEL_PATH = os.path.join(STAGE2_POTATO_DIR, \"stage2_classifier_model_potato.joblib\")\n\nOUTPUT_CSV = \"/kaggle/working/final_pipeline_results_named.csv\"\n\n# ---------------- HELPERS ----------------\ndef load_model(path):\n    obj = joblib.load(path)\n    if isinstance(obj, tuple):\n        return obj\n    if isinstance(obj, dict):\n        return (obj.get(\"scaler\", None), obj.get(\"model\", None))\n    return (None, obj)\n\ndef predict_with_scaler(model_tuple, X):\n    scaler, model = model_tuple\n    if scaler is not None:\n        X = scaler.transform(X)\n    if hasattr(model, \"predict_proba\"):\n        return model.predict_proba(X), model\n    return model.predict(X), model\n\ndef get_labels(probs_or_preds, classes_map):\n    if probs_or_preds.ndim > 1 and probs_or_preds.shape[1] > 1:\n        preds = probs_or_preds.argmax(axis=1)\n    else:\n        preds = probs_or_preds.flatten()\n    return np.array([classes_map[p] for p in preds]), preds\n\n# ---------------- LOAD MODELS ----------------\nstage1_model = load_model(STAGE1_MODEL_PATH)\nstage2_tomato_model = load_model(STAGE2_TOMATO_MODEL_PATH)\nstage2_potato_model = load_model(STAGE2_POTATO_MODEL_PATH)\n\n# ---------------- LOAD EMBEDDINGS ----------------\nX_stage1 = np.load(os.path.join(STAGE1_DIR, \"X_test.npy\"))\ny_stage1 = np.load(os.path.join(STAGE1_DIR, \"y_test.npy\"))\n\nX_tomato = np.load(os.path.join(STAGE2_TOMATO_DIR, \"X_test.npy\"))\ny_tomato = np.load(os.path.join(STAGE2_TOMATO_DIR, \"y_test.npy\"))\n\nX_potato = np.load(os.path.join(STAGE2_POTATO_DIR, \"X_test.npy\"))\ny_potato = np.load(os.path.join(STAGE2_POTATO_DIR, \"y_test.npy\"))\n\nSTAGE1_CLASSES_MAP = {0: \"Potato\", 1: \"Tomato\"}\n\n# ---------------- STAGE 1 ----------------\nstage1_probs, _ = predict_with_scaler(stage1_model, X_stage1)\nstage1_labels, stage1_preds = get_labels(stage1_probs, STAGE1_CLASSES_MAP)\n\n# ---------------- STAGE 2 ----------------\n# Define actual class names\ntomato_class_names = ['Bacterial spot', 'Early blight', 'Healthy', 'Late blight', 'Leaf mold', \n                      'Mosaic virus', 'Septoria leaf spot', 'Spider mites two-spotted spider mite', \n                      'Target spot', 'Yellow leaf curl virus']\ntomato_classes_map = {i: name for i, name in enumerate(tomato_class_names)}\n\npotato_class_names = ['Early blight', 'Healthy', 'Late blight']\npotato_classes_map = {i: name for i, name in enumerate(potato_class_names)}\n\n# Predict Stage 2\ntomato_probs, _ = predict_with_scaler(stage2_tomato_model, X_tomato)\ntomato_labels, _ = get_labels(tomato_probs, tomato_classes_map)\ny_tomato_named = np.array([tomato_classes_map[i] for i in y_tomato])\n\npotato_probs, _ = predict_with_scaler(stage2_potato_model, X_potato)\npotato_labels, _ = get_labels(potato_probs, potato_classes_map)\ny_potato_named = np.array([potato_classes_map[i] for i in y_potato])\n\n# ---------------- EVALUATION ----------------\ntotal = correct_stage1 = correct_stage2 = 0\nclass_stats = []\npipeline_results = []\n\ntomato_index = 0\npotato_index = 0\n\nfor i in range(len(stage1_labels)):\n    true_plant = STAGE1_CLASSES_MAP[y_stage1[i]]\n    pred_plant = stage1_labels[i]\n\n    # Assign correct disease\n    if true_plant == \"Tomato\":\n        true_disease = y_tomato_named[tomato_index]\n        pred_disease = tomato_labels[tomato_index]\n        tomato_index += 1\n    else:\n        true_disease = y_potato_named[potato_index]\n        pred_disease = potato_labels[potato_index]\n        potato_index += 1\n\n    # Per-class stats\n    cls_key = f\"{true_plant}: {true_disease}\"\n    found = next((x for x in class_stats if x[\"Class\"] == cls_key), None)\n    if found is None:\n        class_stats.append({\"Class\": cls_key, \"Correct_Stage1\": 0, \"Correct_Stage2\": 0, \"Total\": 0})\n        found = class_stats[-1]\n\n    found[\"Total\"] += 1\n    total += 1\n\n    if pred_plant == true_plant:\n        correct_stage1 += 1\n        found[\"Correct_Stage1\"] += 1\n        if pred_disease == true_disease:\n            correct_stage2 += 1\n            found[\"Correct_Stage2\"] += 1\n\n    pipeline_results.append({\n        \"true_plant\": true_plant,\n        \"predicted_plant\": pred_plant,\n        \"true_disease\": true_disease,\n        \"predicted_disease\": pred_disease,\n        \"pipeline_correct\": (pred_plant == true_plant and pred_disease == true_disease)\n    })\n\n# ---------------- OVERALL ACCURACY ----------------\nstage1_acc = (correct_stage1 / total) * 100\nstage2_acc = (correct_stage2 / total) * 100\n\nprint(f\"1. Stage 1 (Plant Type) Accuracy: {stage1_acc:.2f}% ({correct_stage1}/{total})\")\nprint(f\"2. Overall Pipeline (Disease) Accuracy: {stage2_acc:.2f}% ({correct_stage2}/{total})\\n\")\n\n# ---------------- PER-CLASS BREAKDOWN ----------------\nprint(\"[PER-CLASS ACCURACY BREAKDOWN]\")\nprint(f\"{'Class':<50} {'Stage1✅':>9} {'Stage2✅':>9} {'Total':>9} {'Acc Stage1%':>15} {'Acc Stage2%':>15}\")\nprint(\"-\" * 100)\nfor stats in sorted(class_stats, key=lambda x: x[\"Class\"]):\n    s1c = stats[\"Correct_Stage1\"]\n    s2c = stats[\"Correct_Stage2\"]\n    t = stats[\"Total\"]\n    s1a = (s1c / t) * 100 if t else 0\n    s2a = (s2c / t) * 100 if t else 0\n    print(f\"{stats['Class']:<50} {s1c:>9} {s2c:>9} {t:>9} {s1a:>15.2f} {s2a:>15.2f}\")\n\n# ---------------- SAVE FULL RESULTS CSV ----------------\ndf_final = pd.DataFrame(pipeline_results)\ndf_final.to_csv(OUTPUT_CSV, index=False)\nprint(f\"\\nFull predictions with disease names saved to {OUTPUT_CSV}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T10:21:43.333961Z","iopub.execute_input":"2025-10-28T10:21:43.334240Z","iopub.status.idle":"2025-10-28T10:21:43.455100Z","shell.execute_reply.started":"2025-10-28T10:21:43.334219Z","shell.execute_reply":"2025-10-28T10:21:43.454257Z"}},"outputs":[{"name":"stdout","text":"1. Stage 1 (Plant Type) Accuracy: 99.16% (3178/3205)\n2. Overall Pipeline (Disease) Accuracy: 94.51% (3029/3205)\n\n[PER-CLASS ACCURACY BREAKDOWN]\nClass                                                Stage1✅   Stage2✅     Total     Acc Stage1%     Acc Stage2%\n----------------------------------------------------------------------------------------------------\nPotato: Early blight                                     165       157       166           99.40           94.58\nPotato: Healthy                                           23        22        24           95.83           91.67\nPotato: Late blight                                      154       151       163           94.48           92.64\nTomato: Bacterial spot                                   336       308       336          100.00           91.67\nTomato: Early blight                                     167       142       167          100.00           85.03\nTomato: Healthy                                          252       241       254           99.21           94.88\nTomato: Late blight                                      298       281       302           98.68           93.05\nTomato: Leaf mold                                        158       148       160           98.75           92.50\nTomato: Mosaic virus                                      69        65        69          100.00           94.20\nTomato: Septoria leaf spot                               291       275       291          100.00           94.50\nTomato: Spider mites two-spotted spider mite             250       239       252           99.21           94.84\nTomato: Target spot                                      213       204       214           99.53           95.33\nTomato: Yellow leaf curl virus                           802       796       807           99.38           98.64\n\nFull predictions with disease names saved to /kaggle/working/final_pipeline_results_named.csv\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# TRAIL","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}